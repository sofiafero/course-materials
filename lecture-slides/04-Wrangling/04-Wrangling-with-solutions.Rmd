---
title: "Topic 4: Data Wrangling in the Tidyverse"
author: "Nick Hagerty* <br> ECNS 460/560 <br> Montana State University"
date: ".smaller[<br> *Parts of these slides are adapted from [“Data Science for Economists”](https://raw.githack.com/uo-ec607/lectures/master/05-tidyverse/05-tidyverse.html) by Grant R. McDermott, used under the [MIT License](https://github.com/uo-ec607/lectures/blob/master/LICENSE). Images are from [ModernDive](https://moderndive.com/3-wrangling.html) by Chester Ismay and Albert Y. Kim, used under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/).]"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts] 
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
      fig_caption: true
---
name: toc

```{css, echo=FALSE}
# CSS for including pauses in printed PDF output (see bottom of lecture)
@media print {
  .has-continuation {
    display: block !important;
  }
}
.small {
  font-size: 90%;
}
.smaller {
  font-size: 80%;
}

```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
knitr::opts_chunk$set(
	fig.align = "center",
	cache = T,
	dpi = 300
)
opts_knit$set(root.dir = "C:/git/covid-example")
```


# Agenda for the next 2-3 weeks

**Where we've been:**

1. R Basics

1. Programming

1. Productivity tools

<br>
**Where we're going:**

1. Data wrangling in the tidyverse

1. Data cleaning

1. Introduce the term project

1. Data acquisition & webscraping

---

# Table of contents

1. [Tidyverse basics](#basics)

1. [Data wrangling with dplyr](#dplyr)

1. [Joining data with dplyr](#joins)

1. [Data tidying with tidyr](#tidyr)

1. [Importing data with readr](#readr)

1. [Summary](#summary)


---
class: inverse, middle
name: basics

# Tidyverse basics

---

# The tidyverse

**A whole "universe" of functions within R**
- The most powerful, intuitive, and popular approach to data cleaning, wrangling, and visualization in R

**Advantages:**
- Consistent philosophy and syntax
- "Verb" based approach makes it more familiar to users of Stata/SAS/SPSS
- Serves as the front-end for many other big data and ML tools

**Why did I make you learn base R to start with?**
- The tidyverse can't do everything
- The best solution to many problems involves a combination of tidyverse and base R
- Ultimately you want to learn about many tools and choose the best one for the job

.footnote[
Note: Another approach with many fans is [**data.table**](http://r-datatable.com/), which you can learn about on your own!
]

---

# Tidyverse vs. base R

There is often a direct correspondence between a tidyverse command and its base R equivalent. 

| tidyverse  |  base |
|---|---|
| `?readr::read_csv`  | `?utils::read.csv` |
|  `?dplyr::if_else` |  `?base::ifelse` |
|  `?tibble::tibble` |  `?base::data.frame` |

Notice these generally follow a `tidyverse::snake_case` vs `base::period.case` rule.

The tidyverse alternative typically offers some enhancements or other useful options (and sometimes restrictions) over its base counterpart.
- Remember: There are always multiple ways to achieve a single goal in R.


---

# Tidying Data

The two most important properties of tidy data are:

1. Each column is a unique variable.
2. Each row is a single observation.

![](img/tidy-1.png)

Tidy data is easier to work with, because you have a consistent way of referring to variables and observations. It then becomes easy to manipulate, visualize, and model.

.smaller[Image is from ["R for Data Science"](https://r4ds.had.co.nz/tidy-data.html) by Hadley Wickham & Garrett Grolemund, used under [CC BY-NC-ND 3.0](https://creativecommons.org/licenses/by-nc-nd/3.0/us/) and is not included under this project's overall CC license.]

---

# Wide vs. Long Formats

Both of these data sets display information on heart rate observed in individuals across 3 different time periods:

```{r echo=FALSE}
wide = data.frame(
  name = c("Wilbur", "Petunia", "Gregory"),
  time1 = c(67, 80, 64),
  time2 = c(56, 90, 50),
  time3 = c(70, 67, 101)
)
wide

long = data.frame(
  name = c("Wilbur", "Petunia", "Gregory", "Wilbur", "Petunia", "Gregory", "Wilbur", "Petunia", "Gregory"),
  time = c(1, 1, 1, 2, 2, 2, 3, 3, 3),
  heartrate = c(67, 80, 64, 56, 90, 50, 70, 67, 10)
)
long
```

Which dataframe is in *tidy* format?

---

# Wide vs. Long Formats

**Wide** data:
- Row = patient. Columns = repeated observations over time.
- Often easier to take in at a glance (as in a spreadsheet).

**Long** data:
- Row = one observation. Columns = ID variables + observed variable.
- Usually easier to clean, merge with other data, and avoid errors.

Tidy data is more likely to be **long**.
- Most R packages have been written assuming your data is in long format.

"Tidy datasets are all alike but every messy dataset is messy in its own way."  
– Hadley Wickham


---

# Tidyverse packages

We need to install and load a couple of packages. Run these preliminaries:

```{r, eval=F}
install.packages('tidyverse')
install.packages('nycflights13')
library(tidyverse)
```
```{r tverse, cache = F, echo=F}
library(tidyverse)
```

--

We see that we have actually loaded a number of packages (which could also be loaded individually): **ggplot2**, **tibble**, **dplyr**, etc.
- We can also see information about the package versions and some [namespace conflicts](https://raw.githack.com/uo-ec607/lectures/master/04-rlang/04-rlang.html#59).

---

# Tidyverse packages

The tidyverse actually comes with a lot more packages than those that are just loaded automatically.
```{r tverse_pkgs}
tidyverse_packages()
```

All of these are super useful
- **lubridate** helps us work with dates
- **rvest** is for webscraping

This lecture will focus on two that are automatically loaded: **dplyr** and **tidyr**.

---

# Pipes: |> or %>%

Pipes take the **output** of one function and feed it into the **first argument** of the next (which you then skip).

`dataframe |> filter(condition)` is equivalent to `filter(dataframe, condition)`.

Note: `|>` on these slides is generated by the two characters `| >`, without the space.

--

<br>
**Older version** of the pipe: `%>%`
* From the `magrittr` package loaded with the tidyverse
* Works identically to `|>` in most situations.

<br>
**Keyboard shortcut:** Ctl/Cmd + Shift + M

* Have to turn on a setting in RStudio options to make `|>` the default

---

# Pipes: |> or %>%

Pipes can dramatically improve the experience of reading and writing code. Compare:

.small[
```{r, eval = F}
## These next two lines of code do exactly the same thing.

mpg |> filter(manufacturer=="audi") |> group_by(model) |> summarize(hwy_mean = mean(hwy))

summarize(group_by(filter(mpg, manufacturer=="audi"), model), hwy_mean = mean(hwy))
```
]

The first line reads from left to right, exactly how you think about the operations.

The second line totally inverts this logical order (the final operation comes first!) 

---

# Pipes: |> or %>%

Best practice is to put each function on its own line and indent. Look how much more readable this is:

```{r pipe}
mpg |> 
  filter(manufacturer == "audi") |> 
  group_by(model) |> 
  summarize(hwy_mean = mean(hwy))
```

Vertical space costs nothing and makes for much more readable/writable code than cramming things horizontally.

All together, this multi-line line of code is called a **pipeline**.


---
class: inverse, middle
name: dplyr

# dplyr

---

# Key dplyr verbs

**There are five key dplyr verbs that you need to learn.**

1. `filter`: Filter (i.e. subset) rows based on their values.

2. `arrange`: Arrange (i.e. reorder) rows based on their values.

3. `select`: Select (i.e. subset) columns by their names: 

4. `mutate`: Create new columns.

5. `summarize`: Collapse multiple rows into a single summary value.<sup>1</sup>

.footnote[
<sup>1</sup> Many sources spell `summarise` with an "s" -- either one works!
]

--

</br>

Let's practice these functions together using the `starwars` data frame that comes pre-packaged with dplyr. 

---

# 1) dplyr::filter

![](img/filter.png)


---

# 1) dplyr::filter

We can chain multiple filter commands with the pipe (`|>`), or just separate them within a single filter command using commas.
```{r filter1}
starwars |> 
  filter( 
    species == "Human", 
    height >= 190
    ) 
```

---

# 1) dplyr::filter

Regular expressions work well too.
```{r filter2}
starwars |> 
  filter(str_detect(name, "Skywalker"))
```

---

# 1) dplyr::filter

A very common `filter` use case is identifying (or removing) missing data cases. 
```{r filter3}
starwars |> 
  filter(is.na(height))
```

--

To remove missing observations, simply use negation: `filter(!is.na(height))`.  
Try this yourself.

---

# 2) dplyr::arrange

![](img/arrange.png)

---

# 2) dplyr::arrange

`arrange` sorts your data frame by a particular column (numerically, or alphabetically)

```{r arrange1, warning=F}
starwars |> 
  arrange(birth_year)
```

---

# 2) dplyr::arrange

We can also arrange items in descending order using `arrange(desc())`.
```{r arrange2}
starwars |> 
  arrange(desc(birth_year))
```

---

# 3) dplyr::select

![](img/select.png)

---

# 3) dplyr::select

Use commas to select multiple columns out of a data frame. (You can also use "first:last" for consecutive columns). Deselect a column with "-".
```{r select1}
starwars |> 
  select(name:skin_color, species, -height)
```

---

# 3) dplyr::select

You can also rename some (or all) of your selected variables in place.
```{r select2}
starwars |>
  select(alias=name, planet=homeworld) 
```

--

If you just want to rename columns without subsetting them, you can use `rename`. Try this!

---

# 3) dplyr::select

The `select(contains(PATTERN))` option provides a nice shortcut in relevant cases.
```{r select3}
starwars |> 
  select(name, contains("color"))
```

Some other selection helpers: `starts_with()`, `ends_with()`, `all_of(c("name1", "name2"))`, `matches()`.

---

# 4) dplyr::mutate

![](img/mutate.png)

---

# 4) dplyr::mutate

You can create new columns from scratch, or (more commonly) as transformations of existing columns.
```{r mutate1}
starwars |> 
  select(name, birth_year) |>
  mutate(dog_years = birth_year * 7) |>
  mutate(comment = paste0(name, " is ", dog_years, " in dog years."))
```

---


# 4) dplyr::mutate

*Note:* `mutate` is order aware. So you can chain multiple mutates in a single call.
```{r mutate2}
starwars |> 
  select(name, birth_year) |>
  mutate(
    dog_years = birth_year * 7,     # Separate with a comma
    comment = paste0(name, " is ", dog_years, " in dog years.")
    )
```

---

# 4) dplyr::mutate

Boolean, logical and conditional operators all work well with `mutate` too.
```{r mutate3}
starwars |> 
  select(name, height) |>
  filter(name %in% c("Luke Skywalker", "Anakin Skywalker")) |> 
  mutate(tall1 = height > 180) |>
  mutate(tall2 = if_else(height > 180, "Tall", "Short"))

```

---

# 4) dplyr::mutate

Lastly, combining `mutate` with `across` allows you to easily perform the same operation on a subset of variables.

```{r, mutate4}
starwars |> 
  select(name:eye_color) |> 
  mutate(across(where(is.character), toupper))
```

---

# 5) dplyr::summarize

![](img/summarize.png)
![](img/group_by.png)


---

# 5) dplyr::summarize

Particularly useful in combination with the `group_by` command.
```{r summ1}
starwars |> 
  group_by(species) |> 
  summarize(mean_height = mean(height))
```

---

# 5) dplyr::summarize

Notice that some of these summarized values are missing. If we want to ignore missing values, use `na.rm = T`:
```{r summ2}
## Much better
starwars |> 
  group_by(species) |> 
  summarize(mean_height = mean(height, na.rm = T))
```

---

# 5) dplyr::summarize

The same `across`-based workflow that we saw with `mutate` a few slides back also works with `summarize`.

```{r, summ3}
starwars |> 
  group_by(species) |>
  summarize(across(where(is.numeric), mean))
```

---

# 5) dplyr::summarize

The same `across`-based workflow that we saw with `mutate` a few slides back also works with `summarize`. Though to add arguments, we have to use an **anonymous function:**

```{r, summ4}
starwars |> 
  group_by(species) |>
  summarize(across(where(is.numeric), ~ mean(.x, na.rm=T)))
```

---

# Other dplyr goodies

`ungroup`: For ungrouping after using `group_by`.
- Use after doing your grouped `summarize` or `mutate` operation, or everything else you do will be super slow.

--

`slice`: Subset rows by position rather than filtering by values.
- E.g. `starwars |> slice(1:10)`

--

`pull`: Extract a column from as a data frame as a vector or scalar.
- E.g. `starwars |> filter(sex=="female") |> pull(height)`

--

`distinct` and `count`: List unique values, with or without their number of appearances.
- E.g. `starwars |> distinct(species)`, or `starwars |> count(species)`
- `count` is equivalent to `group_by` and `summarize` with `n()`:

```{r, eval=F}
starwars |> group_by(species) |> summarize(n = n())
```


---

# Challenge

Take a few minutes to try this on your own:

**List the most common eye colors among female Star Wars characters in descending order of frequency.**



























<!-- No really, try it on your own before scrolling further!! -->






















--

As usual, there are multiple solutions.

.pull-left[
```{r}
starwars |>
  filter(sex == "female") |>
  count(eye_color) |>
  arrange(desc(n))
```
]
.pull-right[
```{r}
starwars |> 
  filter(sex == "female") |>
  group_by(eye_color) |> 
  summarize(n = n()) |>
  arrange(desc(n))
```
]

---

# Storing results in memory

So far we haven't been saving the dataframes that result from our code in memory. Usually, we will want to use them for the next task.

**Solution:** Create a new object each time you write a pipeline.

```{r, eval=FALSE}
women = starwars |> filter(sex == "female")
brown_eyed_women = women |> filter(eye_color == "brown")
```

Resist the temptation to use the same object name. This is called **clobbering** since it overwrites the previous version. It ruins your ability to easily go back to previous steps.

```{r, eval=FALSE}
# DON'T do this
starwars = starwars |> filter(sex == "female")
```

--

By keeping multiple copies of very similar dataframes, will you waste your computer's memory? Usually, no -- R is smart and stores only the changes between objects.

---
class: inverse, middle
name: joins

# Joins

---

# Joining operations

Most data analysis requires combining information from multiple data tables. To combine tables, we use **joins** (similar to `base::merge()`).

![](img/join-inner.png)

--

There are multiple types of joins.

An **inner join** returns a dataframe of all rows that appear in both x and y.
- It keeps *only* rows that appear in both tables.

.smaller[Image is from ["R for Data Science"](https://r4ds.had.co.nz/relational-data.html) by Hadley Wickham & Garrett Grolemund, used under [CC BY-NC-ND 3.0](https://creativecommons.org/licenses/by-nc-nd/3.0/us/) and not included under this resource's overall CC license.]

---

# Joining operations

.pull-left[
A **left join** keeps all rows in x.
- For matched rows, it merges in the values of y
- For unmatched rows, it fills in NA values for the variables coming from y.

A **right join** keeps all rows in y.
- Same as a left join, just reversed.

A **full join** keeps all rows in x and y.

</br>

.smaller[Image is from ["R for Data Science"](https://r4ds.had.co.nz/relational-data.html) by Wickham & Grolemund, used under [CC BY-NC-ND 3.0](https://creativecommons.org/licenses/by-nc-nd/3.0/us/) and not included under this resource's overall CC license.]

]
.pull-right[
![](img/join-outer.png)
]

---

# Joining operations

**Left joins are safer than inner joins**
- It's too easy to lose observations with inner joins
- Left joins preserve all the original observations

**Use the left join** unless you have a strong reason to prefer another.

--

</br>

For the examples that I'm going to show here, we'll need some data sets that come bundled with the [**nycflights13**](http://github.com/hadley/nycflights13) package. 
- Load it now and then inspect these data frames on your own (click on them in your Environment pane).
- Pay attention to what the `year` column means in each data frame.

```{r flights, echo = F}
library(nycflights13)
```
```{r, eval = F}
library(nycflights13)
data(flights)
data(planes)
```

---

# Joining operations

Let's perform a left join on the flights and planes datasets.

```{r join1, eval=F}
flights |> 
  left_join(planes)
```
```{r join2, echo=FALSE}
flights |> 
  left_join(planes) |>
  select(year, month, day, dep_time, arr_time, carrier, flight, tailnum, type, model)
```

---

# Joining operations

(*continued from previous slide*)

Note that dplyr made a reasonable guess about which columns to join on (i.e. columns that share the same name). It also told us its choices: 

```
*## Joining with `by = join_by(year, tailnum)`
```

**What's the problem here?**

--

The variable "year" does not have a consistent meaning across our joining datasets!
- In one it refers to the *year of flight*, in the other it refers to *year of construction*.

--

Luckily, there's an easy way to avoid this problem. 
- Can you figure it out? Try `?dplyr::join`.

































---

# Joining operations

(*continued from previous slide*)

You just need to be more explicit in your join call by using the `by = ` argument.
- Here, it would be good to rename any ambiguous columns to avoid confusion.
```{r join3, eval=F}
flights |>
  left_join(
    planes |> rename(year_built = year),
    by = "tailnum"
    )
```
```{r join4, echo=FALSE}
left_join(
  flights,
  planes |> rename(year_built = year),
  by = "tailnum"
  ) |>
  select(year, month, day, dep_time, arr_time, carrier, flight, tailnum, year_built, type, model) |>
  head(3)
```


---
class: inverse, middle
name: tidyr

# tidyr

---

# Key tidyr verbs

1. `pivot_longer`: Pivot wide data into long format.

2. `pivot_wider`: Pivot long data into wide format.

3. `separate`: Separate (i.e. split) one column into multiple columns.

4. `unite`: Unite (i.e. combine) multiple columns into one.

--

</br>

Which of `pivot_longer` vs `pivot_wider` produces "tidy" data?
  
---

# 1) tidyr::pivot_longer

```{r pivot_longer1}
stocks = data.frame( ## Could use "tibble" instead of "data.frame" if you prefer
  time = as.Date('2009-01-01') + 0:1,
  X = rnorm(2, 10, 1),
  Y = rnorm(2, 10, 2),
  Z = rnorm(2, 10, 5)
  )
stocks
tidy_stocks = stocks |> 
  pivot_longer(cols=X:Z, names_to="stock", values_to="price")
tidy_stocks
```

---

# 2) tidyr::pivot_wider

Now we can use pivot_wider to go back to the original dataframe:

```{r pivot_wider1}
tidy_stocks |> pivot_wider(names_from=stock, values_from=price)
```

Or, we can put it into a new ("transposed") format, in which the observations are stocks and the columns are dates:

```{r pivot_wider2}
tidy_stocks |> pivot_wider(names_from=time, values_from=price)
```


---

# 3) tidyr::separate

`separate` helps when you have more than one value in a single column:

```{r sep1}
economists = data.frame(name = c("Adam_Smith", "Paul_Samuelson", "Milton_Friedman"))
economists
economists |> separate(name, c("first_name", "last_name")) 
```

--

This command is pretty smart. But to avoid ambiguity, you can also specify the separation character with the `sep` argument:

```{r, eval=F}
economists |> separate(name, c("first_name", "last_name"), sep = "_")
```


---

# 3) tidyr::separate

Related is `separate_rows`, for splitting cells with multiple values into multiple rows:
```{r sep2a}
jobs = data.frame(
  name = c("Joe", "Jill"),
  occupation = c("President", "First Lady, Professor, Grandmother")
  ) 
jobs
# Now split out Jill's various occupations into different rows
jobs |> separate_rows(occupation)
```

---

# 3) tidyr::separate

Related is `separate_rows`, for splitting cells with multiple values into multiple rows:
```{r sep2}
jobs = data.frame(
  name = c("Joe", "Jill"),
  occupation = c("President", "First Lady, Professor, Grandmother")
  ) 
jobs
# Now split out Jill's various occupations into different rows
jobs |> separate_rows(occupation, sep = ", ")
```

---

# 4) tidyr::unite

```{r unite1}
gdp = data.frame(
  yr = rep(2016, times = 4),
  mnth = rep(1, times = 4),
  dy = 1:4,
  gdp = rnorm(4, mean = 100, sd = 2)
  )
gdp 
## Combine "yr", "mnth", and "dy" into one "date" column
gdp |> unite(date, c("yr", "mnth", "dy"), sep = "-")
```

---

# 4) tidyr::unite

Note that `unite` will automatically create a character variable.

If you want to convert it to something else (e.g. date or numeric) then you will need to modify it using `mutate`. This example uses the [lubridate](https://lubridate.tidyverse.org/) package's super helpful date conversion functions.

```{r unite3, message=F}
library(lubridate)
gdp_u |> mutate(date = ymd(date))
```


---

# Challenge

**Using `nycflights13`, create a table of average arrival delay (in minutes) by day (in rows) and carrier (in columns).**

Hint: Recall that you can tabulate summary statistics using `group_by` and `summarize`:
```{r}
flights |> 
  group_by(carrier) |> 
  summarize(avg_late = mean(arr_delay, na.rm=T))
```
























<!-- Hey! Don't look! -->























---

# Challenge

**Using `nycflights13`, create a table of average arrival delay (in minutes) by day (in rows) and carrier (in columns).**

Solution:
```{r message=FALSE}
delay_long = flights |> 
  group_by(carrier, day) |> 
  summarize(avg_late = mean(arr_delay, na.rm=T))
delay_wide = delay_long |> 
  pivot_wider(names_from=carrier, values_from=avg_late)
head(delay_wide, 4)
```

Is this data frame tidy?


---
class: inverse, middle
name: readr

# Importing data with readr

---

# Download this data

Most data does not come nicely in R packages! You will download it from somewhere and load it in R.

**Go here:** <https://github.com/nytimes/covid-19-data/tree/master/colleges>   
and click on the **Raw CSV** link.

* This is a list of Covid-19 case counts reported at U.S. colleges and universities between July 2020 and May 2021.

In your browser, **save** this file somewhere sensible on your computer (perhaps a folder you already created to put your work for this class).

Your computer stores all its programs, files, and information in a **filesystem** consisting of a set of nested **folders** or **directories.**

---

# Paths and directories

The **working directory** is your "current location" in the filesystem. What's your current working directory?
```{r}
getwd()
```

* This is an example of a full or **absolute path.**
* It starts with `C:/` on Windows or `/` on Mac.

**Relative paths** are defined relative to the full path of the working directory.
* Let's say your working directory is `"C:/git/ecns-560/"`
* If you had a file saved at `"C:/git/ecns-560/assignment-3/assignment-3.Rmd"`
* Its relative path would be `"assignment-3/assignment-3.Rmd"`

It's always best to use **relative paths,** though you *can* also use an absolute path in any given situation.

---
  
# Setting the working directory
  
You can change your working directory with `setwd(dir)`. Now:

1. **Find the location you saved your CSV file and copy the filepath.**

2. **Use the console in R to set your working directory to that location.**

For example:
```{r, eval=F}
setwd("C:/git/covid-example")
```

**Do not use `setwd()` in scripts.** Setting the working directory is one of the *few exceptions* to the rule that you should always write all your code in scripts.

* Someone else's working directory will be different from yours!
* You want your code to be portable.

---

# Read in data with readr

The tidyverse package `readr` provides lots of options to read data into R. Read in the college Covid data like this:

```{r, message = F}
dat = read_csv("colleges.csv")
```

`View` this data to take a look at it. It automatically formatted everything as a nice and neat data frame!
```{r}
str(dat)
```

---

# Challenge

**Which state had the least total reported Covid-19 cases at colleges and universities?**

Is it Montana?

--















































```{r}
dat2 = dat |>
  group_by(state) |>
  summarize(tot_cases = sum(cases)) |>
  arrange(tot_cases)
dat2
```



---

# Other tips for importing data

* Many things can go wrong with CSV files. When this happens, `read_csv` has many options -- look at the help file.

* You can read files directly from the internet without downloading them first (but you usually shouldn't!):
.smaller[
```{r, eval=F}
url = "https://raw.githubusercontent.com/nytimes/covid-19-data/master/colleges/colleges.csv"
dat = read_csv(url)
```
]

* `write_csv` outputs a dataframe as a CSV to your computer.

* `readxl::read_excel` reads directly from Excel spreadsheets.

* `googlesheets4::read_sheet` reads directly from Google Sheets.

* `haven::read_dta` reads directly from Stata files! (Stata can't read R files....)


---
class: inverse, middle
name: summary

# Summary

---

# Key tidyverse functions

.pull-left[
### dplyr
1. `filter`
2. `arrange`
3. `select`
4. `mutate`
5. `summarize`
]
.pull-right[
### tidyr
1. `pivot_longer`
2. `pivot_wider`
3. `separate`
4. `unite`
]

</br>

.pull-left[
### Miscellaneous
1. Pipes (`|>`)
2. Grouping (`group_by`)
3. Joining (`left_join`)
]
.pull-right[
### Importing data
1. `getwd` & `setwd`
1. `read_csv`
]
